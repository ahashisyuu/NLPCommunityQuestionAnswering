{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'instance'>\n"
     ]
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "import simplejson as json\n",
    "def parse_element(element):\n",
    "    dict_data = dict()\n",
    "    if element.nodeType == element.TEXT_NODE:\n",
    "        if element.data != \" \":\n",
    "            dict_data['data'] = element.data\n",
    "    if element.nodeType not in [element.TEXT_NODE, element.DOCUMENT_NODE, \n",
    "                                element.DOCUMENT_TYPE_NODE]:\n",
    "        for item in element.attributes.items():\n",
    "            dict_data[item[0]] = item[1]\n",
    "    if element.nodeType not in [element.TEXT_NODE, element.DOCUMENT_TYPE_NODE]:\n",
    "        for child in element.childNodes:\n",
    "            child_name, child_dict = parse_element(child)\n",
    "            if child_name in dict_data:\n",
    "                try:\n",
    "                    dict_data[child_name].append(child_dict)\n",
    "                except AttributeError:\n",
    "                    dict_data[child_name] = [dict_data[child_name], child_dict]\n",
    "            else:\n",
    "                dict_data[child_name] = child_dict \n",
    "    return element.nodeName, dict_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dom = minidom.parse('cqa_task3.xml')\n",
    "    print type(dom)\n",
    "    f = open('cqa_task3.json', 'w')\n",
    "    f.write(json.dumps(parse_element(dom), sort_keys=True, indent=4))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2440 entries, 0 to 2439\n",
      "Data columns (total 14 columns):\n",
      "THREAD_SEQUENCE                       2440 non-null object\n",
      "RelQuestion.RELQ_CATEGORY             2440 non-null object\n",
      "RelQuestion.RELQ_DATE                 2440 non-null object\n",
      "RelQuestion.RELQ_ID                   2440 non-null object\n",
      "RelQuestion.RELQ_USERID               2440 non-null object\n",
      "RelQuestion.RELQ_USERNAME             2440 non-null object\n",
      "RelQuestion.RelQClean.#text.data      2440 non-null object\n",
      "RelQuestion.RelQSubject.#text.data    2440 non-null object\n",
      "RELC_DATE                             2440 non-null object\n",
      "RELC_ID                               2440 non-null object\n",
      "RELC_RELEVANCE2RELQ                   2440 non-null object\n",
      "RELC_USERID                           2440 non-null object\n",
      "RELC_USERNAME                         2440 non-null object\n",
      "RelCClean.#text.data                  2440 non-null object\n",
      "dtypes: object(14)\n",
      "memory usage: 266.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srimi/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'color' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ad35f4767849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mis_dup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_dup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Occurrences'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'color' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = pd.read_json('cqa_task3.json')\n",
    "data1.head()\n",
    "df31 = pd.io.json.json_normalize(data1[0][1]['xml'][1]['Thread'])\n",
    "df41 = pd.concat([pd.DataFrame(pd.io.json.json_normalize(x)) for x in df31['RelComment']],ignore_index=True)\n",
    "df41['THREAD_SEQUENCE'] = [ '_'.join(i.split('_')[:2]) for i in df41['RELC_ID']]\n",
    "df51 = pd.concat([df31.set_index('THREAD_SEQUENCE'),df41.set_index('THREAD_SEQUENCE')], axis=1, join='inner').reset_index()\n",
    "df51.head()\n",
    "rem_cols = ['RelQuestion.#text' , 'RelComment', 'RelCBody.#text.data' , 'RelQuestion.RelQBody.#text.data' , \n",
    "            'RelQuestion.RelQBody.#text.data', '#text']\n",
    "[ df51.drop(i, axis=1, inplace=True) for i in rem_cols  ]\n",
    "df51.head()\n",
    "#df51[ df51['RelQuestion.RelQSubject.#text.data'] == 'Best Bank.' ]\n",
    "df51.info()\n",
    "# good_df = df51[df51['RELC_RELEVANCE2RELQ'] == \"Good\"]\n",
    "# print len(good_df)\n",
    "# bad_df = df51[df51['RELC_RELEVANCE2RELQ'] != \"Good\"]\n",
    "# print len(bad_df)\n",
    "# df51.RELC_RELEVANCE2RELQ.unique()\n",
    "# len(good_df.RELC_USERID.unique())\n",
    "# print good_df.columns\n",
    "# new_df = good_df.groupby([u'RelQuestion.RELQ_USERID'])\n",
    "# new_df\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "is_dup = df51['RELC_RELEVANCE2RELQ'].value_counts()\n",
    "is_dup.head()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(is_dup.index, is_dup.values, alpha=0.8, color=color[1])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Values', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color = sns.color_palette()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(is_dup.index, is_dup.values, alpha=0.8, color=color[1])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Values', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952 488\n",
      "14\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, svm\n",
    "train, test = train_test_split(df51, test_size=0.2)\n",
    "print len(train),len(test)\n",
    "col_list =  list(df51.columns)\n",
    "print len(col_list)\n",
    "col_list.remove(u'RELC_RELEVANCE2RELQ')\n",
    "print len(col_list)\n",
    "train_x = train[col_list]\n",
    "train_y = train[u'RELC_RELEVANCE2RELQ']\n",
    "d = train_x.to_dict(orient='records')\n",
    "train_data = zip(d,train_y)\n",
    "test_x = test[col_list]\n",
    "test_y = test[u'RELC_RELEVANCE2RELQ']\n",
    "d = test.to_dict(orient='records')\n",
    "test_data = zip(d,test_y)\n",
    "# classifier = NaiveBayesClassifier.train(train_data)\n",
    "# print(nltk.classify.accuracy(classifier, test_data))\n",
    "# print classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08333333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('bank')\n",
    "# dog.hypernyms()\n",
    "dog = wn.synset('dog.n.01')\n",
    "chair = wn.synset('chair.n.01')\n",
    "dog.path_similarity(chair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: I think after 25 Dec he is busy cleaning his confession booth ;-) [img_assist|nid=58165|title=|desc=|link=none|align=left|width=|height=0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d83cff59ce08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/srimi/anaconda/lib/python2.7/site-packages/sklearn/linear_model/ridge.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \"\"\"\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/srimi/anaconda/lib/python2.7/site-packages/sklearn/linear_model/ridge.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         X, y = check_X_y(X, y, ['csr', 'csc', 'coo'], dtype=np.float64,\n\u001b[0;32m--> 465\u001b[0;31m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[0;32m/Users/srimi/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/srimi/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: I think after 25 Dec he is busy cleaning his confession booth ;-) [img_assist|nid=58165|title=|desc=|link=none|align=left|width=|height=0]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "reg = Ridge(alpha=.1)\n",
    "reg.fit(train_x, train_y)\n",
    "predictions = reg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def preprocess_words(x):\n",
    "    example_sent = x\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_tokens = tokenizer.tokenize(example_sent)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    return ' '.join(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "\n",
    "def get_cosine(text1, text2):\n",
    "     vec1 = text_to_vector(text1)\n",
    "     vec2 = text_to_vector(text2)\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "    \n",
    "df_new['tokenized_question'] = df_new['RelQuestion.RelQClean.#text.data'].apply(lambda row: preprocess_words(str(''.join([c for c in row if ord(c) < 128]))))\n",
    "df_new['tokenized_comment'] = df_new['RelCClean.#text.data'].apply(lambda row: preprocess_words(str(''.join([c for c in row if ord(c) < 128]))))\n",
    "df_new['cosine_similarity_q2c'] = df_new.apply(lambda row : get_cosine( str(row['tokenized_question']),str(row['tokenized_comment']) ),axis =1)\n",
    "df_new['pos_tag_ques'] = df_new['RelQuestion.RelQClean.#text.data'].apply(lambda x: nltk.pos_tag(x.split()) )\n",
    "df_new['pos_tag_ans'] = df_new['RelCClean.#text.data'].apply(lambda x: nltk.pos_tag(x.split()) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>THREAD_SEQUENCE</th>\n",
       "      <th>RelQuestion.RELQ_CATEGORY</th>\n",
       "      <th>RelQuestion.RELQ_DATE</th>\n",
       "      <th>RelQuestion.RELQ_ID</th>\n",
       "      <th>RelQuestion.RELQ_USERID</th>\n",
       "      <th>RelQuestion.RELQ_USERNAME</th>\n",
       "      <th>RelQuestion.RelQClean.#text.data</th>\n",
       "      <th>RelQuestion.RelQSubject.#text.data</th>\n",
       "      <th>RELC_DATE</th>\n",
       "      <th>RELC_ID</th>\n",
       "      <th>RELC_RELEVANCE2RELQ</th>\n",
       "      <th>RELC_USERID</th>\n",
       "      <th>RELC_USERNAME</th>\n",
       "      <th>RelCClean.#text.data</th>\n",
       "      <th>tokenized_question</th>\n",
       "      <th>tokenized_comment</th>\n",
       "      <th>cosine_similarity_q2c</th>\n",
       "      <th>pos_tag_ques</th>\n",
       "      <th>pos_tag_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-07-31 06:46:39</td>\n",
       "      <td>Q268_R16_C1</td>\n",
       "      <td>Bad</td>\n",
       "      <td>U65</td>\n",
       "      <td>Molten Metal</td>\n",
       "      <td>banks are using us ... Talk to those who had t...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>banks using us Talk taken credit card loan know</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(banks, NNS), (are, VBP), (using, VBG), (us, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-07-31 08:10:53</td>\n",
       "      <td>Q268_R16_C2</td>\n",
       "      <td>Bad</td>\n",
       "      <td>U956</td>\n",
       "      <td>Rip Cord</td>\n",
       "      <td>In Qatar that is like saying which is the best...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>In Qatar like saying best STD</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(In, IN), (Qatar, NNP), (that, WDT), (is, VBZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-07-31 10:37:03</td>\n",
       "      <td>Q268_R16_C3</td>\n",
       "      <td>Bad</td>\n",
       "      <td>U5152</td>\n",
       "      <td>arman1arzoo</td>\n",
       "      <td>I'm surprised to see such feedbacks on Qatar b...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>I surprised see feedbacks Qatar banks Is serio...</td>\n",
       "      <td>0.169334</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(I'm, NNP), (surprised, VBD), (to, TO), (see,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-08-01 11:38:21</td>\n",
       "      <td>Q268_R16_C4</td>\n",
       "      <td>Good</td>\n",
       "      <td>U5153</td>\n",
       "      <td>westernindoha</td>\n",
       "      <td>Well Arman; nothing is wrong here with banks; ...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>Well Arman nothing wrong banks I feel par UAE ...</td>\n",
       "      <td>0.091574</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(Well, RB), (Arman;, NNP), (nothing, NN), (is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-08-01 11:45:49</td>\n",
       "      <td>Q268_R16_C5</td>\n",
       "      <td>Good</td>\n",
       "      <td>U492</td>\n",
       "      <td>happygolucky</td>\n",
       "      <td>With QNB for last 4 years plus...no issues...g...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>With QNB last 4 years plus issues great servic...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(With, IN), (QNB, NNP), (for, IN), (last, JJ)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-08-02 06:38:26</td>\n",
       "      <td>Q268_R16_C6</td>\n",
       "      <td>PotentiallyUseful</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>WesternInDoha; that's the information that I a...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>WesternInDoha information I looking answer que...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(WesternInDoha;, NNP), (that's, VBZ), (the, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-08-02 06:46:37</td>\n",
       "      <td>Q268_R16_C7</td>\n",
       "      <td>PotentiallyUseful</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>MoltenMetal; it depend how you are looking on ...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>MoltenMetal depend looking subject matter poin...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(MoltenMetal;, NN), (it, PRP), (depend, VB), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-08-02 06:51:51</td>\n",
       "      <td>Q268_R16_C8</td>\n",
       "      <td>Bad</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>That's new way of description for the Bank's.....</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>That new way description Bank I planing let co...</td>\n",
       "      <td>0.162221</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(That's, NNP), (new, JJ), (way, NN), (of, IN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-08-02 07:10:40</td>\n",
       "      <td>Q268_R16_C9</td>\n",
       "      <td>Bad</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>I don't know if it is the high competition? or...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>I know high competition No competition Is revi...</td>\n",
       "      <td>0.177667</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(I, PRP), (don't, VBP), (know, VB), (if, IN),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>Moving to Qatar</td>\n",
       "      <td>2013-07-31 02:27:08</td>\n",
       "      <td>Q268_R16</td>\n",
       "      <td>U5151</td>\n",
       "      <td>shehabi</td>\n",
       "      <td>Best Bank. // Hi ti all QL's; What bank you ar...</td>\n",
       "      <td>Best Bank.</td>\n",
       "      <td>2013-08-02 12:55:52</td>\n",
       "      <td>Q268_R16_C10</td>\n",
       "      <td>Good</td>\n",
       "      <td>U5153</td>\n",
       "      <td>westernindoha</td>\n",
       "      <td>Sheabi; the reason behind it; is that most peo...</td>\n",
       "      <td>Best Bank Hi ti QL What bank using Are using b...</td>\n",
       "      <td>Sheabi reason behind people QL low income henc...</td>\n",
       "      <td>0.152145</td>\n",
       "      <td>[(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...</td>\n",
       "      <td>[(Sheabi;, NNP), (the, DT), (reason, NN), (beh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  THREAD_SEQUENCE RelQuestion.RELQ_CATEGORY RelQuestion.RELQ_DATE  \\\n",
       "0        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "1        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "2        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "3        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "4        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "5        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "6        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "7        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "8        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "9        Q268_R16           Moving to Qatar   2013-07-31 02:27:08   \n",
       "\n",
       "  RelQuestion.RELQ_ID RelQuestion.RELQ_USERID RelQuestion.RELQ_USERNAME  \\\n",
       "0            Q268_R16                   U5151                   shehabi   \n",
       "1            Q268_R16                   U5151                   shehabi   \n",
       "2            Q268_R16                   U5151                   shehabi   \n",
       "3            Q268_R16                   U5151                   shehabi   \n",
       "4            Q268_R16                   U5151                   shehabi   \n",
       "5            Q268_R16                   U5151                   shehabi   \n",
       "6            Q268_R16                   U5151                   shehabi   \n",
       "7            Q268_R16                   U5151                   shehabi   \n",
       "8            Q268_R16                   U5151                   shehabi   \n",
       "9            Q268_R16                   U5151                   shehabi   \n",
       "\n",
       "                    RelQuestion.RelQClean.#text.data  \\\n",
       "0  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "1  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "2  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "3  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "4  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "5  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "6  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "7  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "8  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "9  Best Bank. // Hi ti all QL's; What bank you ar...   \n",
       "\n",
       "  RelQuestion.RelQSubject.#text.data            RELC_DATE       RELC_ID  \\\n",
       "0                         Best Bank.  2013-07-31 06:46:39   Q268_R16_C1   \n",
       "1                         Best Bank.  2013-07-31 08:10:53   Q268_R16_C2   \n",
       "2                         Best Bank.  2013-07-31 10:37:03   Q268_R16_C3   \n",
       "3                         Best Bank.  2013-08-01 11:38:21   Q268_R16_C4   \n",
       "4                         Best Bank.  2013-08-01 11:45:49   Q268_R16_C5   \n",
       "5                         Best Bank.  2013-08-02 06:38:26   Q268_R16_C6   \n",
       "6                         Best Bank.  2013-08-02 06:46:37   Q268_R16_C7   \n",
       "7                         Best Bank.  2013-08-02 06:51:51   Q268_R16_C8   \n",
       "8                         Best Bank.  2013-08-02 07:10:40   Q268_R16_C9   \n",
       "9                         Best Bank.  2013-08-02 12:55:52  Q268_R16_C10   \n",
       "\n",
       "  RELC_RELEVANCE2RELQ RELC_USERID  RELC_USERNAME  \\\n",
       "0                 Bad         U65   Molten Metal   \n",
       "1                 Bad        U956       Rip Cord   \n",
       "2                 Bad       U5152    arman1arzoo   \n",
       "3                Good       U5153  westernindoha   \n",
       "4                Good        U492   happygolucky   \n",
       "5   PotentiallyUseful       U5151        shehabi   \n",
       "6   PotentiallyUseful       U5151        shehabi   \n",
       "7                 Bad       U5151        shehabi   \n",
       "8                 Bad       U5151        shehabi   \n",
       "9                Good       U5153  westernindoha   \n",
       "\n",
       "                                RelCClean.#text.data  \\\n",
       "0  banks are using us ... Talk to those who had t...   \n",
       "1  In Qatar that is like saying which is the best...   \n",
       "2  I'm surprised to see such feedbacks on Qatar b...   \n",
       "3  Well Arman; nothing is wrong here with banks; ...   \n",
       "4  With QNB for last 4 years plus...no issues...g...   \n",
       "5  WesternInDoha; that's the information that I a...   \n",
       "6  MoltenMetal; it depend how you are looking on ...   \n",
       "7  That's new way of description for the Bank's.....   \n",
       "8  I don't know if it is the high competition? or...   \n",
       "9  Sheabi; the reason behind it; is that most peo...   \n",
       "\n",
       "                                  tokenized_question  \\\n",
       "0  Best Bank Hi ti QL What bank using Are using b...   \n",
       "1  Best Bank Hi ti QL What bank using Are using b...   \n",
       "2  Best Bank Hi ti QL What bank using Are using b...   \n",
       "3  Best Bank Hi ti QL What bank using Are using b...   \n",
       "4  Best Bank Hi ti QL What bank using Are using b...   \n",
       "5  Best Bank Hi ti QL What bank using Are using b...   \n",
       "6  Best Bank Hi ti QL What bank using Are using b...   \n",
       "7  Best Bank Hi ti QL What bank using Are using b...   \n",
       "8  Best Bank Hi ti QL What bank using Are using b...   \n",
       "9  Best Bank Hi ti QL What bank using Are using b...   \n",
       "\n",
       "                                   tokenized_comment  cosine_similarity_q2c  \\\n",
       "0    banks using us Talk taken credit card loan know               0.157135   \n",
       "1                      In Qatar like saying best STD               0.000000   \n",
       "2  I surprised see feedbacks Qatar banks Is serio...               0.169334   \n",
       "3  Well Arman nothing wrong banks I feel par UAE ...               0.091574   \n",
       "4  With QNB last 4 years plus issues great servic...               0.000000   \n",
       "5  WesternInDoha information I looking answer que...               0.000000   \n",
       "6  MoltenMetal depend looking subject matter poin...               0.000000   \n",
       "7  That new way description Bank I planing let co...               0.162221   \n",
       "8  I know high competition No competition Is revi...               0.177667   \n",
       "9  Sheabi reason behind people QL low income henc...               0.152145   \n",
       "\n",
       "                                        pos_tag_ques  \\\n",
       "0  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "1  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "2  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "3  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "4  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "5  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "6  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "7  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "8  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "9  [(Best, NNP), (Bank., NNP), (//, NNP), (Hi, NN...   \n",
       "\n",
       "                                         pos_tag_ans  \n",
       "0  [(banks, NNS), (are, VBP), (using, VBG), (us, ...  \n",
       "1  [(In, IN), (Qatar, NNP), (that, WDT), (is, VBZ...  \n",
       "2  [(I'm, NNP), (surprised, VBD), (to, TO), (see,...  \n",
       "3  [(Well, RB), (Arman;, NNP), (nothing, NN), (is...  \n",
       "4  [(With, IN), (QNB, NNP), (for, IN), (last, JJ)...  \n",
       "5  [(WesternInDoha;, NNP), (that's, VBZ), (the, D...  \n",
       "6  [(MoltenMetal;, NN), (it, PRP), (depend, VB), ...  \n",
       "7  [(That's, NNP), (new, JJ), (way, NN), (of, IN)...  \n",
       "8  [(I, PRP), (don't, VBP), (know, VB), (if, IN),...  \n",
       "9  [(Sheabi;, NNP), (the, DT), (reason, NN), (beh...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()\n",
    "each_df = df_new[ df_new['THREAD_SEQUENCE'] == 'Q268_R16']\n",
    "#each_df[['RELC_RELEVANCE2RELQ','cosine_similarity_q2c']]\n",
    "each_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
